{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib, cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import math\n",
    "import os\n",
    "import itertools\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_2_train = \"Task2Dataset/Training/png/\"\n",
    "task_2_test = \"Task2Dataset/TestWithoutRotations/images/\"\n",
    "task_2_test_annotations = \"Task2Dataset/TestWithoutRotations/annotations/\"\n",
    "\n",
    "task_3_test_annotations = \"Task3AdditionalTestDataset/annotations/\"\n",
    "task_3_test = \"Task3AdditionalTestDataset/images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_features(train_folder):\n",
    "    \n",
    "    train_points = {}\n",
    "    train_descriptors = {}\n",
    "    \n",
    "    sift = cv2.SIFT_create(nOctaveLayers=5, nfeatures=1000, contrastThreshold=0.1)\n",
    "\n",
    "    for train_image in os.listdir(train_folder):\n",
    "        image = cv2.imread(os.path.join(train_folder, train_image), 0)\n",
    "        \n",
    "        pt, desc = sift.detectAndCompute(image, None)\n",
    "        \n",
    "        train_points[train_image] = pt\n",
    "        train_descriptors[train_image] = desc\n",
    "\n",
    "    return train_descriptors, train_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotations(annotation_folder):\n",
    "    annotations = {}\n",
    "\n",
    "    for annotation_file in os.listdir(annotation_folder):\n",
    "        image_name = os.path.basename(annotation_file)\n",
    "        annotation_file = open(os.path.join(annotation_folder, annotation_file), \"r\")\n",
    "        annotation_lines = annotation_file.readlines()\n",
    "        image_annot = []\n",
    "        for line in annotation_lines:\n",
    "            image_annot.append(line.split(\",\")[0])\n",
    "        annotations[image_name] = image_annot\n",
    "    return annotations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sift_matches(train_pt, train_desc, test_image_path):\n",
    "\n",
    "    test_image = cv2.imread(test_image_path, 0)\n",
    "\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    test_points, test_descriptor = sift.detectAndCompute(test_image, None)\n",
    "\n",
    "    matcher = cv2.BFMatcher_create()\n",
    "\n",
    "    matches = matcher.knnMatch(train_desc, test_descriptor, 2)\n",
    "    retained_matches = []\n",
    "    for one, two in matches:\n",
    "        #change threshold; lower to reduce matches retained\n",
    "        if one.distance < 0.3*two.distance:\n",
    "            retained_matches.append([one])\n",
    "\n",
    "    return retained_matches\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(train_folder, test_image_folder, test_annotation_folder):\n",
    "    total_total = 0\n",
    "    total_correct = 0\n",
    "    for test_image in os.listdir(test_image_folder):\n",
    "        \n",
    "        train_pts, train_desc = get_train_features(train_folder)\n",
    "        \n",
    "        scores = {}\n",
    "        \n",
    "        for image, desc in train_desc.items():\n",
    "\n",
    "            matches = sift_matches(train_desc[image], train_pts[image], os.path.join(test_image_folder, test_image))\n",
    "            scores[image.split(\"-\")[1].split(\".\")[0]] = len(matches)\n",
    "\n",
    "        scores = dict(sorted(scores.items(), key=lambda x: x[1], reverse=True))\n",
    "        annotations = get_annotations(test_annotation_folder)\n",
    "\n",
    "        scores = dict(itertools.islice(scores.items(), len(annotations)))\n",
    "\n",
    "        # note - need to refactor task 3 test annotations from .csv to .txt before use\n",
    "        test_annotations = annotations[test_image.split(\".\")[0]+\".txt\"]\n",
    "        true_positives, false_positives, true_negatives, false_negatives = 0,0,0,0 \n",
    "        for annotation in test_annotations:\n",
    "            if annotation in scores:\n",
    "                true_positives += 1\n",
    "            else:\n",
    "                false_positives += 1\n",
    "                false_negatives += 1\n",
    "        total = false_positives + true_positives\n",
    "        total_total+=total\n",
    "        total_correct+=true_positives\n",
    "        print(test_image, \":\", true_positives, \"/\", total)\n",
    "    print(\"Total performance:\", total_correct, \"/\", total_total)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_image_1.png : 3 / 4\n",
      "test_image_10.png : 4 / 5\n",
      "test_image_11.png : 3 / 4\n",
      "test_image_12.png : 3 / 5\n",
      "test_image_13.png : 4 / 5\n",
      "test_image_14.png : 2 / 4\n",
      "test_image_15.png : 2 / 4\n",
      "test_image_16.png : 3 / 5\n",
      "test_image_17.png : 5 / 5\n",
      "test_image_18.png : 4 / 5\n",
      "test_image_19.png : 4 / 4\n",
      "test_image_2.png : 4 / 5\n",
      "test_image_20.png : 4 / 4\n",
      "test_image_3.png : 2 / 4\n",
      "test_image_4.png : 4 / 5\n",
      "test_image_5.png : 1 / 5\n",
      "test_image_6.png : 2 / 4\n",
      "test_image_7.png : 4 / 5\n",
      "test_image_8.png : 3 / 5\n",
      "test_image_9.png : 4 / 4\n",
      "Total performance: 65 / 91\n"
     ]
    }
   ],
   "source": [
    "evaluate(task_2_train, task_2_test, task_2_test_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_image_1.png : 3 / 4\n",
      "test_image_10.png : 2 / 4\n",
      "test_image_11.png : 3 / 4\n",
      "test_image_12.png : 2 / 4\n",
      "test_image_13.png : 2 / 4\n",
      "test_image_14.png : 2 / 5\n",
      "test_image_15.png : 3 / 4\n",
      "test_image_16.png : 3 / 4\n",
      "test_image_17.png : 2 / 4\n",
      "test_image_18.png : 2 / 5\n",
      "test_image_19.png : 2 / 4\n",
      "test_image_2.png : 4 / 4\n",
      "test_image_20.png : 3 / 4\n",
      "test_image_3.png : 2 / 4\n",
      "test_image_4.png : 3 / 5\n",
      "test_image_5.png : 3 / 5\n",
      "test_image_6.png : 5 / 5\n",
      "test_image_7.png : 4 / 5\n",
      "test_image_8.png : 3 / 4\n",
      "test_image_9.png : 2 / 4\n",
      "Total performance: 55 / 86\n"
     ]
    }
   ],
   "source": [
    "evaluate(task_2_train, task_3_test, task_3_test_annotations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cm30080",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
