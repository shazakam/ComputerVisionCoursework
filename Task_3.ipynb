{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib, cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans, DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "import math\n",
    "import os\n",
    "import itertools\n",
    "import random\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_2_train = \"Task2Dataset/Training/png/\"\n",
    "task_2_test = \"Task2Dataset/TestWithoutRotations/images/\"\n",
    "task_2_test_annotations = \"Task2Dataset/TestWithoutRotations/annotations/\"\n",
    "\n",
    "task_3_test_annotations = \"Task3AdditionalTestDataset/annotations/\"\n",
    "task_3_test = \"Task3AdditionalTestDataset/images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#refactored to class structure to simplify parameter tuning and testing of different matching algorithms, outlier rejection etc\n",
    "class SIFT:\n",
    "    #c_thresh=0.09 to get 0.03 used by lowe as used in paper\n",
    "    def __init__(self, n_octaves=3, n_feat=0, c_thresh=0.09, e_thresh=10, lowe_thresh=0.7, ransac_thresh=5.0, sigma=1.6, k=2, min_matches=10, train_folder=\"\", test_folder=\"\", test_annotation_folder=\"\", matcher=cv2.FlannBasedMatcher()):\n",
    "        \"\"\"\n",
    "        Initialise parameters, by default set to OpenCV default values.\n",
    "        Allows easy testing of parameters by simply calling SIFT(n_octaves=5), for example\n",
    "        \"\"\"\n",
    "        self.n_octaves=n_octaves #num octaves used in computing DoG pyramid\n",
    "        self.n_feat=n_feat #num features to retain when getting keypoints/descriptors\n",
    "        self.c_thresh=c_thresh #contrast threshold used in SIFT feature detection\n",
    "        self.e_thresh=e_thresh #edge threshold in SIFT feature detection\n",
    "        self.lowe_thresh=lowe_thresh #threshold for lowe's ratio test\n",
    "        self.ransac_thresh=ransac_thresh #threshold used in RANSAC outlier rejection\n",
    "        self.sigma=sigma #dictates level of gaussian blur in DoG pyramid\n",
    "        self.k=k #number of nearest neighbours obtained in knnmatch\n",
    "        self.min_matches=min_matches #number of matches required to calculate homography - kinda redundant\n",
    "        self.train_folder=train_folder\n",
    "        self.test_folder=test_folder\n",
    "        self.test_annotation_folder=test_annotation_folder\n",
    "        self.train_pts = {} # store keypoints of training images\n",
    "        self.train_desc = {} # store descriptors of training images\n",
    "        self.test_points = {}\n",
    "        self.test_desc = {}\n",
    "        self.train_feat_count = {} #store number of features found for training image for scoring mechanism\n",
    "        self.matcher = matcher #FlannBasedMatcher or BFMatcher\n",
    "        self.matches = [] #store retained matches\n",
    "        self.homography_matrix = None #store homography matrix\n",
    "        self.inlier_mask = \"\" #store inlier mask\n",
    "        self.test_annotations = {} #store annotations for test images\n",
    "        self.num_train_images=0\n",
    "        self.sift = cv2.SIFT_create(self.n_feat, self.n_octaves, self.c_thresh, self.e_thresh, self.sigma)\n",
    "        self.cluster_desc = []\n",
    "\n",
    "    def get_label(self, file):\n",
    "        \"\"\"\n",
    "        Helper function to get label from filename\n",
    "        i.e. 001-this-is-the-label.png returns this-is-the-label\n",
    "        \"\"\"\n",
    "        return file.split(\"-\", 1)[1].split(\".\")[0]\n",
    "    \n",
    "    def get_file_name(self, file):\n",
    "        \"\"\"\n",
    "        Helper function to get full file name barring extension\n",
    "        i.e. 001-name.png returns 001-name\n",
    "        \"\"\"\n",
    "        return file.split(\".\")[0]\n",
    "        \n",
    "    def get_sift_train_features(self):\n",
    "        \"\"\"\n",
    "        Gets SIFT keypoints and descriptors for all images in train folder\n",
    "        Stored under dictionaries for easy access using image name\n",
    "        \"\"\"\n",
    "        \n",
    "        for train_image in os.listdir(self.train_folder):\n",
    "            image = cv2.imread(os.path.join(self.train_folder, train_image), 0)\n",
    "            #image = cv2.medianBlur(image, 5)\n",
    "            pt, desc = self.sift.detectAndCompute(image, None)\n",
    "            self.train_pts[self.get_file_name(train_image)] = pt\n",
    "            self.train_desc[self.get_file_name(train_image)] = desc\n",
    "            self.train_feat_count[self.get_file_name(train_image)] = len(pt)\n",
    "            self.num_train_images+=1\n",
    "\n",
    "    def get_sift_test_features(self):\n",
    "        for test_image in os.listdir(self.test_folder):\n",
    "            image = cv2.imread(os.path.join(self.test_folder, test_image), 0)\n",
    "            #image = cv2.medianBlur(image, 5)\n",
    "\n",
    "            pt, desc = self.sift.detectAndCompute(image, None)\n",
    "            test_image = self.get_file_name(test_image)\n",
    "            self.test_points[test_image] = pt\n",
    "            self.test_desc[test_image] = desc\n",
    "\n",
    "    def get_annotations(self):\n",
    "        \"\"\"\n",
    "        Get annotations for each test image\n",
    "        \"\"\"\n",
    "        for annotation_file in os.listdir(self.test_annotation_folder):\n",
    "            \n",
    "            image_name = self.get_file_name(annotation_file)\n",
    "            annotation_file = open(os.path.join(self.test_annotation_folder, annotation_file), \"r\")\n",
    "            \n",
    "            annotation_lines = annotation_file.readlines()\n",
    "            image_annot = []\n",
    "            \n",
    "            for line in annotation_lines:\n",
    "                image_annot.append(line.split(\",\")[0])\n",
    "            \n",
    "            self.test_annotations[image_name] = image_annot\n",
    "\n",
    "    def is_bound_box(self,vertices):\n",
    "        \"\"\"\n",
    "        Additional checks for bounding boxes\n",
    "        \"\"\"\n",
    "        if np.any(vertices < 0) or np.any(vertices > 512):\n",
    "            return False\n",
    "        distances =[]\n",
    "        for i in range(4):\n",
    "            j = (i+1)%4\n",
    "            distances.append(math.sqrt((vertices[i][0][0] - vertices[j][0][0])**2 + (vertices[i][0][1] - vertices[j][0][1])**2))\n",
    "        \n",
    "        if np.abs(distances[0] - distances[2]) > 0.8 and np.abs(distances[1] - distances[3]) > 0.8:\n",
    "            return False\n",
    "        \n",
    "        a = [vertices[1][0][0] - vertices[0][0][0],vertices[1][0][1] - vertices[0][0][1] ]\n",
    "        b = [ vertices[2][0][0] - vertices[1][0][0],vertices[2][0][1] - vertices[1][0][1]]\n",
    "        dot_product = np.dot(a,b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
    "        \n",
    "        if np.abs(dot_product) > 0.1:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def draw_boxes(self, train_image_name, test_image_name, homography_method, good_matches):\n",
    "        \"\"\"\n",
    "        Draw bounding boxes given train and test images\n",
    "        \"\"\"\n",
    "        assert self.train_desc, \"Run SIFT.get_sift_train_features()\"\n",
    "        assert self.test_desc, \"Run SIFT.get_sift_test_features()\"\n",
    "        canvas = cv2.imread(f\"./{test_image_name}_boxed.png\")\n",
    "        train_image = cv2.imread(os.path.join(self.train_folder, train_image_name + \".png\"))\n",
    "        h, w = train_image.shape[:2]\n",
    "        \n",
    "        src_pts = np.float32([self.train_pts[self.get_file_name(train_image_name)][m[0].queryIdx].pt for m in good_matches]).reshape(-1,1,2)        \n",
    "        dst_pts = np.float32([self.test_points[test_image_name][m[0].trainIdx].pt for m in good_matches]).reshape(-1,1,2)\n",
    "        \n",
    "        if len(src_pts) < 4 or len(dst_pts) < 4:\n",
    "            return\n",
    "        M, mask = cv2.findHomography(src_pts, dst_pts, homography_method, self.ransac_thresh)\n",
    "        if M is None:\n",
    "            return\n",
    "        \n",
    "        pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "        dst = cv2.perspectiveTransform(pts, M)\n",
    "        \n",
    "        if not self.is_bound_box(dst):\n",
    "            return\n",
    "\n",
    "        canvas = cv2.polylines(canvas, [np.int32(dst)], True, (0,0,255), 2, cv2.LINE_AA)\n",
    "        centroid = np.int32(dst.mean(axis=0)[0])\n",
    "        centroid[0]-=55\n",
    "        centroid[1]-=37\n",
    "        centroid = tuple(centroid)\n",
    "\n",
    "        cv2.putText(canvas, self.get_label(train_image_name), centroid, cv2.FONT_HERSHEY_COMPLEX, 0.4, (255,0,0), 1, cv2.LINE_AA )\n",
    "        cv2.imwrite(f\"./{test_image_name}_boxed.png\", canvas)\n",
    "\n",
    "\n",
    "    def sift_matches_lowes(self, train_image_name, test_image_name):\n",
    "        \"\"\"\n",
    "        Match SIFT features, using Lowe's Ratio Test as a means of outlier rejection\n",
    "        \"\"\"\n",
    "\n",
    "        #match features\n",
    "        matches = self.matcher.knnMatch(self.train_desc[self.get_file_name(train_image_name)], self.test_desc[test_image_name], self.k)\n",
    "\n",
    "        #lowe's ratio test\n",
    "        for one, two in matches:\n",
    "            if one.distance < self.lowe_thresh * two.distance:\n",
    "                self.matches.append([one])\n",
    "        self.draw_boxes(train_image_name, test_image_name, 0, self.matches)\n",
    "    \n",
    "\n",
    "    def sift_matches_ransac(self, train_image_name, test_image_name):\n",
    "        \"\"\"\n",
    "        Match SIFT features, obtain homography matrix and use RANSAC/inlier mask for outlier rejection\n",
    "        \"\"\"\n",
    "\n",
    "        #match features\n",
    "        matches = self.matcher.knnMatch(self.train_desc[self.get_file_name(train_image_name)], self.test_desc[test_image_name], self.k)\n",
    "        if len(matches) > self.min_matches:\n",
    "            #if sufficient matches to compute homography, calculate source/dest points\n",
    "            src_pts = np.float32([self.train_pts[self.get_file_name(train_image_name)][m[0].queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "            dst_pts = np.float32([self.test_points[test_image_name][m[0].trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "            \n",
    "            #get homography matrix + mask\n",
    "            H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, self.ransac_thresh)\n",
    "            self.homography_matrix = H\n",
    "            inlier_mask = mask.ravel().tolist()\n",
    "            #extract inlier matches\n",
    "            for i in range(len(matches)):\n",
    "                if inlier_mask[i]:\n",
    "                    self.matches.append(matches[i])\n",
    "        else:\n",
    "            #cannot compute homography\n",
    "            self.matches=[]\n",
    "\n",
    "        self.draw_boxes(train_image_name, test_image_name, 0, self.matches)\n",
    "\n",
    "\n",
    "    def count_features(self, image_path):\n",
    "        \"\"\"\n",
    "        Count number of features in an image based on number of outlines (contours) produced\n",
    "        \"\"\"\n",
    "        image = cv2.medianBlur(cv2.imread(image_path, 0), 25)\n",
    "        null, threshold_image = cv2.threshold(image, 250, 255, cv2.THRESH_BINARY_INV)\n",
    "        outlines, null = cv2.findContours(threshold_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        return len(outlines)\n",
    "    \n",
    "    def compare_scores_annot(self, scores, test_image):\n",
    "        \"\"\"\n",
    "        Compares annotations file with identified matches\n",
    "        \"\"\"\n",
    "\n",
    "        true_pos, false_pos, true_neg, false_neg = 0, 0, 0, 0\n",
    "        print(\"----------------------------------------------------\")\n",
    "        print(f\"Correct labels: {self.test_annotations[test_image]}\")\n",
    "        print(f\"Our labels: {scores}\")\n",
    "        for train_image in scores.keys():\n",
    "\n",
    "            if self.get_label(train_image) in self.test_annotations[test_image]:\n",
    "                true_pos+=1\n",
    "            else:\n",
    "                false_pos+=1\n",
    "                false_neg+=1\n",
    "        total = true_pos+false_pos\n",
    "        print(f\"{test_image}: {true_pos}/{(true_pos+false_pos)}\")\n",
    "        print(\"----------------------------------------------------\")\n",
    "\n",
    "        true_neg = self.num_train_images - false_neg - true_pos - false_pos\n",
    "\n",
    "        return true_pos, false_pos, true_neg, false_neg\n",
    "    \n",
    "    def eval(self, lowes=False, normalise=False):\n",
    "        \"\"\"\n",
    "        Get score for a specific test image\n",
    "        \n",
    "        Normalise == False: score is purely a ranking of the number of matches between train images and a test image\n",
    "        Normalise == True: normalise number of matches by number of features extracted from train image\n",
    "        \n",
    "        If lowes=false, use ransac. Vice versa.\n",
    "        \"\"\"\n",
    "        tp, fp, tn, fn = 0, 0, 0, 0\n",
    "        for test_image in os.listdir(self.test_folder):\n",
    "            scores = {}\n",
    "            canvas = cv2.imread(os.path.join(self.test_folder, test_image))\n",
    "            cv2.imwrite(f\"./{self.get_file_name(test_image)}_boxed.png\", canvas)\n",
    "            for image, desc in self.train_desc.items():\n",
    "                self.matches = []\n",
    "\n",
    "                if lowes:\n",
    "                    self.sift_matches_lowes(image, self.get_file_name(test_image))\n",
    "                else:\n",
    "                    self.sift_matches_ransac(image, self.get_file_name(test_image))\n",
    "\n",
    "                if normalise and self.train_feat_count[image]:\n",
    "                    \n",
    "                    scores[self.get_file_name(image)] = len(self.matches) / self.train_feat_count[image]\n",
    "                else:\n",
    "                    scores[self.get_file_name(image)] = len(self.matches)\n",
    "\n",
    "            scores = dict(sorted(scores.items(), key=lambda x: x[1], reverse=True))\n",
    "            scores = dict(itertools.islice(scores.items(), self.count_features(os.path.join(self.test_folder, test_image))))\n",
    "            # [print(key) for key in scores.keys()]\n",
    "            # [self.draw_boxes(train_image, self.get_file_name(test_image), 0, self.matches) for train_image in scores.keys()]\n",
    "            test_image = self.get_file_name(test_image)\n",
    "            true_pos, false_pos, true_neg, false_neg = self.compare_scores_annot(scores, test_image)\n",
    "            tp+=true_pos\n",
    "            tn+=true_neg\n",
    "            fp+=false_pos\n",
    "            fn+=false_neg\n",
    "            \n",
    "        acc = ((tp+tn)/(tp+tn+fp+fn)) # accuracy\n",
    "        tpr = (tp)/(tp+fn) # true positive rate\n",
    "        fpr = (fp)/(fp+tn) # false positive rate\n",
    "        return acc, tpr, fpr\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = SIFT(train_folder=<pass_train_folder_here>, \n",
    "            test_folder=<pass_test_image_folder>, \n",
    "            test_annotation_folder=<pass_test_annotation_folder>, \n",
    "            matcher=cv2.BFMatcher_create(), #vary matcher subject to desired use\n",
    "            <pass_parameters_here> # see init for parameter customisation\n",
    "            )\n",
    "\n",
    "sift.get_annotations()\n",
    "sift.get_sift_train_features()\n",
    "sift.get_sift_test_features()\n",
    "sift.eval(normalise=True, lowes=True) # see eval() for information on customisation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within draw_bound_boxes(), comment out is_bound_box check for increased accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### This will output results in the following format\n",
    "---------------------------------------------------\n",
    "Correct labels: ['barn', 'hospital', 'university', 'hotel']\n",
    "Our labels: {'011-trash': 0.3194444444444444, '036-hotel': 0.12727272727272726, '015-barn': 0.10714285714285714, '048-hospital': 0.06779661016949153}\n",
    "test_image_1: 3/4\n",
    "----------------------------------------------------\n",
    "\n",
    "## Bounding box images will be output in the root directory, under test_image_x_boxed.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alex\\AppData\\Local\\Temp\\ipykernel_19472\\1156727353.py:107: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dot_product = np.dot(a,b)/(np.linalg.norm(a)*np.linalg.norm(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "Correct labels: ['barn', 'hospital', 'university', 'hotel']\n",
      "Our labels: {'011-trash': 0.3194444444444444, '036-hotel': 0.12727272727272726, '015-barn': 0.10714285714285714, '048-hospital': 0.06779661016949153}\n",
      "test_image_1: 3/4\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "Correct labels: ['post-office', 'police', 'fire-station', 'lighthouse']\n",
      "Our labels: {'046-fire-station': 0.2962962962962963, '001-lighthouse': 0.27906976744186046, '037-post-office': 0.27906976744186046, '035-police': 0.18333333333333332}\n",
      "test_image_10: 4/4\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "Correct labels: ['supermarket', 'bus-stop', 'church', 'bus']\n",
      "Our labels: {'007-supermarket': 0.3137254901960784, '006-church': 0.2, '012-bus': 0.0967741935483871, '048-hospital': 0.06779661016949153}\n",
      "test_image_11: 3/4\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "Correct labels: ['car', 'factory', 'bus-stop', 'gas-station']\n",
      "Our labels: {'011-trash': 0.3472222222222222, '022-car': 0.3125, '042-tractor': 0.189873417721519, '047-restaurant': 0.13793103448275862}\n",
      "test_image_12: 1/4\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "Correct labels: ['telephone-booth', 'flower', 'field', 'solar-panel']\n",
      "Our labels: {'031-field': 0.47058823529411764, '021-solar-panel': 0.192, '001-lighthouse': 0.0, '002-bike': 0.0}\n",
      "test_image_13: 2/4\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "Correct labels: ['solar-panel', 'atm', 'fire-station', 'telephone-booth', 'trash']\n",
      "Our labels: {'046-fire-station': 0.25925925925925924, '020-atm': 0.23684210526315788, '030-telephone-booth': 0.12, '032-van': 0.0425531914893617, '011-trash': 0.041666666666666664}\n",
      "test_image_14: 4/5\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "Correct labels: ['telephone-booth', 'supermarket', 'tractor', 'house']\n",
      "Our labels: {'007-supermarket': 0.3333333333333333, '030-telephone-booth': 0.28, '042-tractor': 0.11392405063291139, '016-house': 0.09302325581395349}\n",
      "test_image_15: 4/4\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "Correct labels: ['hospital', 'prison', 'fountain', 'ferris-wheel']\n",
      "Our labels: {'024-fountain': 0.1794871794871795, '044-ferris-wheel': 0.06338028169014084, '019-prison': 0.021739130434782608, '048-hospital': 0.01694915254237288}\n",
      "test_image_16: 4/4\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "Correct labels: ['house', 'police', 'water-well', 'gas-station']\n",
      "Our labels: {'013-water-well': 0.14035087719298245, '027-gas-station': 0.1, '016-house': 0.09302325581395349, '046-fire-station': 0.07407407407407407}\n",
      "test_image_17: 3/4\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "Correct labels: ['flower', 'bank', 'fire-station', 'post-office', 'bus-stop']\n",
      "Our labels: {'046-fire-station': 0.14814814814814814, '037-post-office': 0.11627906976744186, '014-flower': 0.0975609756097561, '040-bus-stop': 0.08064516129032258, '018-bank': 0.047619047619047616}\n",
      "test_image_18: 5/5\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "Correct labels: ['prison', 'car', 'windmill', 'fire-station']\n",
      "Our labels: {'046-fire-station': 0.3333333333333333, '028-government': 0.08333333333333333, '019-prison': 0.06521739130434782, '025-factory': 0.05660377358490566}\n",
      "test_image_19: 2/4\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "Correct labels: ['courthouse', 'bench', 'lighthouse', 'bank']\n",
      "Our labels: {'001-lighthouse': 0.4186046511627907, '018-bank': 0.14285714285714285, '010-bench': 0.11538461538461539, '008-courthouse': 0.11428571428571428}\n",
      "test_image_2: 4/4\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "Correct labels: ['bank', 'atm', 'water-well', 'silo']\n",
      "Our labels: {'018-bank': 0.42857142857142855, '020-atm': 0.3684210526315789, '005-silo': 0.16666666666666666, '013-water-well': 0.15789473684210525}\n",
      "test_image_20: 4/4\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "Correct labels: ['trash', 'house', 'fire-station', 'solar-panel']\n",
      "Our labels: {'011-trash': 0.375, '046-fire-station': 0.2962962962962963, '021-solar-panel': 0.192, '032-van': 0.10638297872340426}\n",
      "test_image_3: 3/4\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "Correct labels: ['shop', 'museum', 'barn', 'courthouse', 'bus-stop']\n",
      "Our labels: {'008-courthouse': 0.14285714285714285, '026-shop': 0.1276595744680851, '040-bus-stop': 0.08064516129032258, '015-barn': 0.03571428571428571, '045-museum': 0.03125}\n",
      "test_image_4: 5/5\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "Correct labels: ['billboard', 'bus-stop', 'bridge', 'windmill', 'field']\n",
      "Our labels: {'034-billboard': 0.21052631578947367, '031-field': 0.17647058823529413, '041-windmill': 0.11920529801324503, '008-courthouse': 0.11428571428571428, '012-bus': 0.11290322580645161}\n",
      "test_image_5: 3/5\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "Correct labels: ['silo', 'university', 'cinema', 'cemetery', 'bike']\n",
      "Our labels: {'050-cemetery': 0.4, '005-silo': 0.1388888888888889, '039-university': 0.09090909090909091, '020-atm': 0.07894736842105263, '046-fire-station': 0.07407407407407407}\n",
      "test_image_6: 3/5\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "Correct labels: ['field', 'gas-station', 'bank', 'flower', 'government']\n",
      "Our labels: {'018-bank': 0.42857142857142855, '031-field': 0.4117647058823529, '027-gas-station': 0.26, '014-flower': 0.14634146341463414, '028-government': 0.08333333333333333}\n",
      "test_image_7: 5/5\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "Correct labels: ['windmill', 'post-office', 'bench', 'shop']\n",
      "Our labels: {'011-trash': 0.3611111111111111, '037-post-office': 0.23255813953488372, '032-van': 0.0851063829787234, '010-bench': 0.07692307692307693}\n",
      "test_image_8: 2/4\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "Correct labels: ['cemetery', 'fountain', 'school', 'silo']\n",
      "Our labels: {'011-trash': 0.3611111111111111, '042-tractor': 0.20253164556962025, '050-cemetery': 0.2, '047-restaurant': 0.10344827586206896}\n",
      "test_image_9: 1/4\n",
      "----------------------------------------------------\n",
      "(0.958, 0.7558139534883721, 0.022975929978118162)\n"
     ]
    }
   ],
   "source": [
    "sift = SIFT(train_folder=task_2_train, \n",
    "            test_folder=task_3_test, \n",
    "            test_annotation_folder=task_3_test_annotations, \n",
    "            matcher=cv2.BFMatcher_create(),\n",
    "            #e_thresh=6,\n",
    "            lowe_thresh=0.4,)\n",
    "            #n_octaves=4)\n",
    "\n",
    "sift.get_annotations()\n",
    "sift.get_sift_train_features()\n",
    "sift.get_sift_test_features()\n",
    "print(sift.eval(normalise=True, lowes=True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cm30080",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
